{
  
    
        "post0": {
            "title": "My final project",
            "content": "Introduction - This dataset combines 15 years (2006 – 2020) of the Cooperative Congressional Election Study (CCES). The CCES is an online survey conducted around November of each year, asking a range of questions on political behavior and public opinion. Its principal investigators are Stephen Ansolabehere, Sam Luks, and Brian Schaffner. . Dataset content - Each year’s CCES asks hundreds of questions, many of which change from year to year. This cumulative file only includes a subset of those questions that are standard and important. It standardizes (harmonizes) its values across years and creates a few new variables too. Users can still merge in their year-specific questions of interest easily into this cumulative file and take advantage of its standardized variables. . import pandas as pd . Importing pandas library for working with relational and labeled data . df = pd.read_stata(&#39;cumulative_2006-2020.dta&#39;) . A Stata dta version is provided. cumulative_2006-2020.dta can be read by Stata . Reading my CCES - Cooperative Congressional Election Study dataset . Variables: The sections below provide summary statistics and more information on each variable. . Administration - year: CCES year, starttime: Start time, tookpost: Took post-election wave . Weights - weight: Survey weight (Year-Specific), weight_cumulative: Survey weight (Cumulative), weight_post: Survey weight for post-election wave, rvweight: Survey weights to validated registered voters, rvweight_post: Survey weights to validated registered voters, post-election wave . Geography A series of variables for the respondent’s location: – state: State (FIPS) – state_post: State (FIPS), post-election – st: State abbreviation (FIPS) – st_post: State abbreviation (FIPS), post-election – dist: Congressional district number in current Congress – dist_post: Congressional district number in current Congress, post-election – dist_up: Congressional district number for upcoming Congress – dist_up_post: Congressional district number for upcoming Congress, post-election – cd: Congressional district in current Congress – cd_post: Congressional district in current Congress, post-election – cd_up: Congressional district in upcoming Congress – cd_up_post: Congressional district in upcoming Congress, post-election – zipcode: Zipcode (lookupzip) – county_fips: County of residence . Demographics : gender: Gender “Are you male or female?” . birthyr: Year of birth “In what year were you born?” . age: Ag Approximate age computed from the year of survey minus Year of Birth . educ: Education “What is the highest level of education you have completed?” . race: Race “What racial or ethnic group best describes you?” . hispanic: Hispanic “Are you of Spanish, Latino, or Hispanic origin or descent? [Asked if response to race is not Hispanic]” . citizen: Citizenship [Based on self-report for immigration status] . religion: Religion “What is your present religion, if any? . Family Status marstat: Marital Status “What is your marital status?” . ownhome: Home Ownership “Do you own your home or pay rent?” . has_child: Parent of Young Children “Are you the parent or guardian of any children under the age of 18?” . no_milstat: Military Status (None) [Based on military household question; neither respondent nor immediate family has served] . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 531755 entries, 0 to 531754 Data columns (total 93 columns): # Column Non-Null Count Dtype -- -- 0 year 531755 non-null int32 1 case_id 531755 non-null object 2 weight 531755 non-null float64 3 weight_cumulative 531755 non-null float64 4 state 531755 non-null category 5 st 531755 non-null category 6 cong 531755 non-null category 7 cong_up 531755 non-null category 8 state_post 352626 non-null category 9 st_post 352626 non-null category 10 dist 531755 non-null int32 11 dist_up 531755 non-null int32 12 cd 531755 non-null object 13 cd_up 531755 non-null object 14 dist_post 352625 non-null float64 15 dist_up_post 352625 non-null float64 16 cd_post 531755 non-null object 17 cd_up_post 531755 non-null object 18 zipcode 531755 non-null object 19 county_fips 531755 non-null object 20 tookpost 420956 non-null category 21 weight_post 201136 non-null float64 22 rvweight 40017 non-null float64 23 rvweight_post 36949 non-null float64 24 starttime 531755 non-null datetime64[ns] 25 pid3 522801 non-null category 26 pid3_leaner 528739 non-null category 27 pid7 528739 non-null category 28 ideo5 529941 non-null category 29 gender 531755 non-null category 30 birthyr 531755 non-null int32 31 age 531755 non-null int32 32 race 531755 non-null category 33 hispanic 404598 non-null category 34 citizen 505832 non-null category 35 educ 531688 non-null category 36 marstat 530169 non-null category 37 faminc 530180 non-null category 38 union 487744 non-null category 39 union_hh 485132 non-null category 40 employ 521462 non-null category 41 no_healthins 452471 non-null category 42 has_child 484434 non-null category 43 ownhome 486713 non-null category 44 no_milstat 521661 non-null category 45 religion 494305 non-null category 46 economy_retro 530757 non-null category 47 newsint 494702 non-null category 48 approval_pres 530925 non-null category 49 approval_rep 523629 non-null category 50 approval_sen1 526928 non-null category 51 approval_sen2 526158 non-null category 52 approval_gov 529260 non-null category 53 intent_pres_08 30195 non-null category 54 intent_pres_12 52243 non-null category 55 intent_pres_16 63002 non-null category 56 intent_pres_20 48951 non-null category 57 voted_pres_08 166602 non-null category 58 voted_pres_12 157972 non-null category 59 voted_pres_16 185127 non-null category 60 voted_pres_20 45652 non-null category 61 intent_pres_party 170489 non-null category 62 voted_pres_party 398093 non-null category 63 vv_regstatus 323535 non-null category 64 vv_party_gen 235335 non-null category 65 vv_party_prm 235335 non-null category 66 vv_turnout_gvm 359956 non-null category 67 vv_turnout_pvm 323535 non-null category 68 intent_rep 391502 non-null category 69 intent_rep_party 281560 non-null category 70 voted_rep 296137 non-null category 71 voted_rep_party 271594 non-null category 72 intent_gov 185853 non-null category 73 intent_gov_party 147881 non-null category 74 voted_gov 137592 non-null category 75 voted_gov_party 128640 non-null category 76 intent_sen 263541 non-null category 77 intent_sen_party 203241 non-null category 78 voted_sen 199506 non-null category 79 voted_sen_party 188355 non-null category 80 intent_rep_chosen 531755 non-null object 81 intent_sen_chosen 531755 non-null object 82 intent_gov_chosen 531755 non-null object 83 voted_rep_chosen 531755 non-null object 84 voted_sen_chosen 531755 non-null object 85 voted_gov_chosen 531755 non-null object 86 rep_current 531755 non-null object 87 rep_icpsr 531755 non-null object 88 sen1_current 531755 non-null object 89 sen1_icpsr 531755 non-null object 90 sen2_current 531755 non-null object 91 sen2_icpsr 531755 non-null object 92 gov_current 531755 non-null object dtypes: category(60), datetime64[ns](1), float64(7), int32(5), object(20) memory usage: 158.2+ MB . Displaying the features of my dataset . Observations in even years include indicators for validated voting, which means that YouGov has matched survey respondents’ personal identifiable information to public voter files, which in turn officially record whether a person has voted or not. Validation is often completed in the summer following the election. . Validations : vv_regstatus: Validated registration status, vv_party_gen: Validated registered party,vv_party_prm: Validated registered Primary party, . Turnout: vv_turnout_gvm: Validated turnout General Election, vv_turnout_pvm: Validated turnout Primary Election (Congressional) . Partisan Identity pid3: Partisan identity (3 point) “Generally speaking, do you think of yourself as a . . . ?” . pid7: Partisan identity (7 point) . pid3_leaner: Partisan identity (including leaners) . ideo5: Ideology (5 point) “In general, how would you describe your own political viewpoint?” . Economics and Income faminc: Family Income “Thinking back over the last year, what was your family’s annual income? . employ: Employment Status “Which of the following best describes your current employment status?” . no_healthins: Uninsured Based on health insurance question; respondent has none of the insurance options given . union: Union membership “Are you a member of a union?&quot; . union_hh: Union membership in household “Other than yourself, is any member of your household a union member?” . economy_retro: Retrospective economy “OVER THE PAST YEAR the nation’s economy has . . . ?” . News Interest newsint: News Interest “Some people seem to follow what’s going on in government and public affairs most of the time, whether there’s an election going on or not. Others aren’t that interested. Would you say you follow what’s going on in government and public affairs ..” . Vote Choice Variables: A note on the terms &quot;intent&quot; and &quot;voted&quot;: In this dataset we make the distinction between “intent” / “preference” vs. “voted” / “vote choice”. “Intent” (or “preference”) refers to the response to the prospective question of the sort “who would you vote for?” in the pre-election wave. “Vote choice” refers to the response to the retrospective question of the sort “in the election this November, who did you vote for?” Response to the vote choice questions coalesces both post-election wave responses (the bulk of the responses) and pre-election respondents who reported having already voted early. In 2018, it also coalesces the responses to the straight ticket party option so that those who selected the Republican straight party ticket in the applicable states will appear to have voted for the Republican candidate in all offices. The straight ticket party option was not asked in other years. The category “Did Not Vote” is recorded only when the respondent selects that option. Respondents who have missing values for intent or vote choice can also be non-voters for a variety of reasons. . My analysis will be based out this section below: . Presidential Vote intent_pres_party: President preference party . voted_pres_party: President vote in last election . intent_pres_12: 2012 President preference (before voting) “In the race for President of the United States, who do you prefer?” . intent_pres_16: 2016 President preference (before voting) “Which candidate did you prefer for President of the United States?” . intent_pres_20: 2020 President preference (before voting) “Which candidate for President of the United States do you prefer?” . voted_pres_08: 2008 President vote choice (after voting) “2008: For which candidate for President of the United States did you vote? . voted_pres_12: 2012 President vote choice (after voting) “2012: For whom did you vote for President of the United States? 2016: In 2012, who did you vote for in the election for President? . voted_pres_16: 2016 President vote choice (after voting) “2017: In the election for U.S. President, who did you vote for? 2016: For whom did you vote for President of the United States? . voted_pres_20: 2020 President vote choice (after voting) 2020: For whom did you vote for President of the United States? . df.describe() . year weight weight_cumulative dist dist_up dist_post dist_up_post weight_post rvweight rvweight_post birthyr age . count 531755.000000 | 531755.000000 | 531755.000000 | 531755.000000 | 531755.000000 | 352625.000000 | 352625.000000 | 201136.000000 | 40017.000000 | 36949.000000 | 531755.000000 | 531755.000000 | . mean 2013.735534 | 0.999999 | 0.925234 | 9.370851 | 9.374443 | 9.270069 | 9.273208 | 1.000000 | 1.000000 | 1.000000 | 1964.278813 | 49.456722 | . std 4.260923 | 1.044919 | 1.255373 | 9.735636 | 9.740023 | 9.667857 | 9.667396 | 1.222933 | 0.819795 | 0.920531 | 17.330081 | 16.615643 | . min 2006.000000 | 0.000000 | 0.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 0.000010 | 0.000100 | 0.000100 | 1900.000000 | 18.000000 | . 25% 2010.000000 | 0.447918 | 0.303355 | 3.000000 | 3.000000 | 3.000000 | 3.000000 | 0.460138 | 0.552093 | 0.526200 | 1951.000000 | 35.000000 | . 50% 2014.000000 | 0.733179 | 0.551475 | 6.000000 | 6.000000 | 6.000000 | 6.000000 | 0.701619 | 0.817733 | 0.789011 | 1962.000000 | 51.000000 | . 75% 2018.000000 | 1.161106 | 1.058625 | 12.000000 | 12.000000 | 12.000000 | 12.000000 | 1.077100 | 1.204087 | 1.170535 | 1979.000000 | 62.000000 | . max 2020.000000 | 15.000647 | 24.029732 | 53.000000 | 53.000000 | 53.000000 | 53.000000 | 15.002276 | 15.000026 | 15.000086 | 2002.000000 | 109.000000 | . Displaying the summary statistics of the features . mydata=df[[&#39;year&#39;,&#39;age&#39;,&#39;dist&#39;,&#39;voted_pres_16&#39;]] . mydata_new=mydata[mydata[&#39;year&#39;] == 2016] . mydata_final =mydata_new[mydata_new[&#39;dist&#39;] &lt; 6 ] . mydata_final . year age dist voted_pres_16 . 309955 2016 | 47 | 2 | Donald Trump | . 309956 2016 | 22 | 2 | Donald Trump | . 309959 2016 | 34 | 2 | Hilary Clinton | . 309960 2016 | 53 | 5 | NaN | . 309961 2016 | 54 | 4 | Donald Trump | . ... ... | ... | ... | ... | . 374549 2016 | 49 | 3 | NaN | . 374551 2016 | 30 | 5 | NaN | . 374552 2016 | 38 | 1 | NaN | . 374553 2016 | 29 | 2 | NaN | . 374554 2016 | 42 | 2 | NaN | . 29204 rows × 4 columns . mydata_final = mydata_final.head(5000) . mydata_final . year age dist voted_pres_16 . 309955 2016 | 47 | 2 | Donald Trump | . 309956 2016 | 22 | 2 | Donald Trump | . 309959 2016 | 34 | 2 | Hilary Clinton | . 309960 2016 | 53 | 5 | NaN | . 309961 2016 | 54 | 4 | Donald Trump | . ... ... | ... | ... | ... | . 320222 2016 | 56 | 4 | Donald Trump | . 320224 2016 | 60 | 1 | Donald Trump | . 320226 2016 | 70 | 1 | Hilary Clinton | . 320227 2016 | 69 | 4 | Donald Trump | . 320230 2016 | 24 | 2 | Hilary Clinton | . 5000 rows × 4 columns . Filtering my dataset - Viewing only 2016 data and first five districts. Also I have subset to have only first 5000 rows for legibility. . print(mydata_final[&#39;age&#39;].mean()) . 57.2946 . print(mydata_final[&#39;age&#39;].median()) . 59.0 . print(mydata_final[&#39;age&#39;].std()) . 14.408057789509751 . Calculating the mean, median and standard deviation using the age column . mydata_final[[&#39;voted_pres_16&#39;]].sample(5) . voted_pres_16 . 313968 Hilary Clinton | . 317323 Donald Trump | . 316114 NaN | . 315402 Donald Trump | . 315674 NaN | . mydata_final.shape . (5000, 4) . mydata_final.describe() . year age dist . count 5000.0 | 5000.000000 | 5000.000000 | . mean 2016.0 | 57.294600 | 2.739800 | . std 0.0 | 14.408058 | 1.413682 | . min 2016.0 | 18.000000 | 1.000000 | . 25% 2016.0 | 49.000000 | 1.000000 | . 50% 2016.0 | 59.000000 | 3.000000 | . 75% 2016.0 | 67.000000 | 4.000000 | . max 2016.0 | 95.000000 | 5.000000 | . mydata_final.loc[309956] . year 2016 age 22 dist 2 voted_pres_16 Donald Trump Name: 309956, dtype: object . mydata_final.loc[309959] . year 2016 age 34 dist 2 voted_pres_16 Hilary Clinton Name: 309959, dtype: object . mydata_final[&#39;voted_pres_16&#39;].value_counts().sort_values().plot(kind=&#39;barh&#39;) . &lt;AxesSubplot:&gt; . Visualizing my variable of interest before regression analysis . Logistic regression is a classification algorithm. It is used to predict a binary outcome based on a set of independent variables. . Ok, so what does this mean in general? A binary outcome is one where there are only two possible scenarios—either the event happens (1) or it does not happen (0). Independent variables are those variables or factors which may influence the outcome (or dependent variable). . Logistic regression is the correct type of analysis to use when you’re working with binary data. You know you’re dealing with binary data when the output or dependent variable is dichotomous or categorical in nature; in other words, if it fits into one of two categories (such as “yes” or “no”, “pass” or “fail”, and so on). . For my analysis, I&#39;m working on 2016 data myoutcome variable is the president who won the 2016 election - whether Hillary clinton or not. My analysis to count all votes and segregate them as Hillary vs everybody else. So I assumed 0 as all other possibilities and 1 as the outcome for Hillary Clinton. . from sklearn.preprocessing import LabelEncoder . labelEncoder = LabelEncoder() mydata_final[&#39;voted_pres_16&#39;] = labelEncoder.fit_transform(mydata_final[&#39;voted_pres_16&#39;].astype(str)) . C: Users LENOVO AppData Local Temp/ipykernel_2960/2958351148.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy mydata_final[&#39;voted_pres_16&#39;] = labelEncoder.fit_transform(mydata_final[&#39;voted_pres_16&#39;].astype(str)) . mydata_final.loc[309956] . year 2016 age 22 dist 2 voted_pres_16 1 Name: 309956, dtype: int32 . mydata_final.loc[309959] . year 2016 age 34 dist 2 voted_pres_16 2 Name: 309959, dtype: int32 . mydata_final[&#39;voted_pres_16&#39;] = mydata_final[&#39;voted_pres_16&#39;].replace( to_replace=[0,1,3,4,5], value=0) . C: Users LENOVO AppData Local Temp/ipykernel_2960/2538898829.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy mydata_final[&#39;voted_pres_16&#39;] = mydata_final[&#39;voted_pres_16&#39;].replace( . mydata_final[&#39;voted_pres_16&#39;] = mydata_final[&#39;voted_pres_16&#39;].replace( to_replace=[2], value=1) . C: Users LENOVO AppData Local Temp/ipykernel_2960/3174617103.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy mydata_final[&#39;voted_pres_16&#39;] = mydata_final[&#39;voted_pres_16&#39;].replace( . print(mydata_final[&#39;voted_pres_16&#39;].value_counts()) . 0 2932 1 2068 Name: voted_pres_16, dtype: int64 . mydata_final.boxplot(by =&#39;voted_pres_16&#39;, column =[&#39;age&#39;]) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;age&#39;}, xlabel=&#39;voted_pres_16&#39;&gt; . Logistic regression - Converting my variable of interest to binary . from sklearn.model_selection import train_test_split . features = mydata_final.drop(&#39;voted_pres_16&#39;,axis=1) target = mydata_final[&#39;voted_pres_16&#39;] . x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2) . print(x_train.shape) print(y_train.shape) . (4000, 3) (4000,) . print(x_test.shape) print(y_test.shape) . (1000, 3) (1000,) . x_train . year age dist . 315681 2016 | 57 | 4 | . 310968 2016 | 43 | 3 | . 314513 2016 | 54 | 3 | . 312033 2016 | 44 | 3 | . 317829 2016 | 75 | 3 | . ... ... | ... | ... | . 313154 2016 | 53 | 5 | . 318630 2016 | 66 | 1 | . 311714 2016 | 57 | 2 | . 319633 2016 | 64 | 5 | . 317891 2016 | 59 | 2 | . 4000 rows × 3 columns . x_test . year age dist . 317525 2016 | 53 | 5 | . 314694 2016 | 55 | 4 | . 318646 2016 | 63 | 4 | . 320081 2016 | 33 | 5 | . 317512 2016 | 73 | 2 | . ... ... | ... | ... | . 313398 2016 | 64 | 1 | . 312238 2016 | 31 | 4 | . 316761 2016 | 33 | 3 | . 310868 2016 | 60 | 3 | . 318621 2016 | 54 | 1 | . 1000 rows × 3 columns . y_train . 315681 1 310968 0 314513 0 312033 1 317829 0 .. 313154 0 318630 1 311714 1 319633 1 317891 0 Name: voted_pres_16, Length: 4000, dtype: int64 . y_test . 317525 0 314694 0 318646 0 320081 1 317512 0 .. 313398 0 312238 0 316761 1 310868 1 318621 1 Name: voted_pres_16, Length: 1000, dtype: int64 . from sklearn.linear_model import LogisticRegression from sklearn.metrics import confusion_matrix . logistic_model = LogisticRegression(penalty=&#39;l2&#39;, solver=&#39;liblinear&#39;) . logistic_model.fit(x_train, y_train) . LogisticRegression(solver=&#39;liblinear&#39;) . y_pred = logistic_model.predict(x_test) . confusion_matrix = confusion_matrix(y_test, y_pred) confusion_matrix . array([[595, 0], [405, 0]], dtype=int64) . print(&quot;Training score : &quot;, logistic_model.score(x_train, y_train)) . Training score : 0.58425 . from sklearn.metrics import accuracy_score, precision_score, recall_score . acc = accuracy_score(y_test, y_pred) pre = precision_score(y_test, y_pred) recall = recall_score(y_test, y_pred) . C: Users LENOVO anaconda3 lib site-packages sklearn metrics _classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . print(&#39;Accuracy : &#39; , acc) print(&#39;Precision Score : &#39;, pre) print(&#39;Recall Score : &#39;, recall) . Accuracy : 0.595 Precision Score : 0.0 Recall Score : 0.0 . I&#39;m unsure why the precision and recall scores are for 0 for this analysis. I have tried subsetting the data and trying various combinations - I was able to achieve the accuracy score from 50% to 85% but the precision and recall scores remain the same. I was lost but my professor told me to give decision tree classifier a try. . Classification is a two-step process, learning step and prediction step. In the learning step, the model is developed based on given training data. In the prediction step, the model is used to predict the response for given data. Decision Tree is one of the easiest and popular classification algorithms to understand and interpret. It can be utilized for both classification and regression kind of problem. . Decision Tree Classifier Building in Scikit-learn Importing Required Libraries and loading the required libraries here . import numpy as np import matplotlib.pyplot as plt . dcdata=df[[&#39;year&#39;,&#39;age&#39;,&#39;dist&#39;,&#39;voted_pres_16&#39;]] . new=dcdata[dcdata[&#39;year&#39;] == 2016] . final =new[new[&#39;dist&#39;] &lt; 6 ] . final=final.head(5000) . final.dropna() . year age dist voted_pres_16 . 309955 2016 | 47 | 2 | Donald Trump | . 309956 2016 | 22 | 2 | Donald Trump | . 309959 2016 | 34 | 2 | Hilary Clinton | . 309961 2016 | 54 | 4 | Donald Trump | . 309965 2016 | 70 | 1 | Hilary Clinton | . ... ... | ... | ... | ... | . 320222 2016 | 56 | 4 | Donald Trump | . 320224 2016 | 60 | 1 | Donald Trump | . 320226 2016 | 70 | 1 | Hilary Clinton | . 320227 2016 | 69 | 4 | Donald Trump | . 320230 2016 | 24 | 2 | Hilary Clinton | . 4382 rows × 4 columns . final.isna().sum() . year 0 age 0 dist 0 voted_pres_16 618 dtype: int64 . final[&#39;voted_pres_16&#39;].unique() . [&#39;Donald Trump&#39;, &#39;Hilary Clinton&#39;, NaN, &#39;Other / Someone Else&#39;, &#39;Not Sure / Don&#39;t Recall&#39;, &#39;Did Not Vote&#39;] Categories (5, object): [&#39;Hilary Clinton&#39; &lt; &#39;Donald Trump&#39; &lt; &#39;Other / Someone Else&#39; &lt; &#39;Did Not Vote&#39; &lt; &#39;Not Sure / Don&#39;t Recall&#39;] . final_clean=final.fillna(&quot;Not Sure / Don&#39;t Recall&quot;) . final_clean.isna().sum() . year 0 age 0 dist 0 voted_pres_16 0 dtype: int64 . import pandas as pd from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier from sklearn.model_selection import train_test_split # Import train_test_split function from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation . col_names = [&#39;year&#39;,&#39;age&#39;,&#39;dist&#39;,&#39;voted_pres_16&#39;] . Feature Selection: Here, you need to divide given columns into two types of variables dependent(or target variable) and independent variable(or feature variables). . feature_cols = [&#39;year&#39;,&#39;age&#39;,&#39;dist&#39;] X = final_clean[feature_cols] # Features y = final_clean.voted_pres_16 # Target variable . X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test . Splitting Data To understand model performance, dividing the dataset into a training set and a test set is a good strategy. . I&#39;ve split the dataset by using function train_test_split() by passing 3 parameters features, target, and test_set size. . Decision tree classifier for my variable of interest. . Building Decision Tree Model Let&#39;s create a Decision Tree Model using Scikit-learn. . clf = DecisionTreeClassifier() # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test) . Evaluating Model Let&#39;s estimate, how accurately the classifier or model can predict the type of cultivars. . Accuracy can be computed by comparing actual test set values and predicted values. . print(&quot;Accuracy:&quot;,metrics.accuracy_score(y_test, y_pred)) . Accuracy: 0.4106666666666667 . Decision tree classifier for my variable of interest using entropy . clf = DecisionTreeClassifier(criterion=&quot;entropy&quot;, max_depth=4) # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test) # Model Accuracy, how often is the classifier correct? print(&quot;Accuracy:&quot;,metrics.accuracy_score(y_test, y_pred)) . Accuracy: 0.42 . final_clean[&#39;voted_pres_16&#39;] . 309955 Donald Trump 309956 Donald Trump 309959 Hilary Clinton 309960 Not Sure / Don&#39;t Recall 309961 Donald Trump ... 320222 Donald Trump 320224 Donald Trump 320226 Hilary Clinton 320227 Donald Trump 320230 Hilary Clinton Name: voted_pres_16, Length: 5000, dtype: category Categories (5, object): [&#39;Hilary Clinton&#39; &lt; &#39;Donald Trump&#39; &lt; &#39;Other / Someone Else&#39; &lt; &#39;Did Not Vote&#39; &lt; &#39;Not Sure / Don&#39;t Recall&#39;] . Another approach to decision tree classification model evaluation . final_clean[&#39;voted_pres_16&#39;].unique() . [&#39;Donald Trump&#39;, &#39;Hilary Clinton&#39;, &#39;Not Sure / Don&#39;t Recall&#39;, &#39;Other / Someone Else&#39;, &#39;Did Not Vote&#39;] Categories (5, object): [&#39;Hilary Clinton&#39; &lt; &#39;Donald Trump&#39; &lt; &#39;Other / Someone Else&#39; &lt; &#39;Did Not Vote&#39; &lt; &#39;Not Sure / Don&#39;t Recall&#39;] . class_group = final_clean.groupby(&#39;voted_pres_16&#39;).apply(lambda x: len(x)) class_group . voted_pres_16 Hilary Clinton 2068 Donald Trump 1907 Other / Someone Else 386 Did Not Vote 6 Not Sure / Don&#39;t Recall 633 dtype: int64 . class_group.plot(kind=&#39;bar&#39;, grid=False) . &lt;AxesSubplot:xlabel=&#39;voted_pres_16&#39;&gt; . from sklearn.preprocessing import LabelEncoder from sklearn.feature_extraction import DictVectorizer cols_to_retain = [&#39;year&#39;,&#39;age&#39;,&#39;dist&#39;] X_feature = final_clean[cols_to_retain] X_dict = X_feature.T.to_dict().values() # turn list of dicts into a numpy array vect = DictVectorizer(sparse=False) X_vector = vect.fit_transform(X_dict) # print the features # vect.get_feature_names() # 0 to 14 is train set X_Train = X_vector[:-1] # 15th is test set X_Test = X_vector[-1:] # Used to vectorize the class label le = LabelEncoder() y_train = le.fit_transform(final_clean[&#39;voted_pres_16&#39;][:-1]) . from sklearn import tree clf = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;) clf = clf.fit(X_Train,y_train) . le.inverse_transform(clf.predict(X_Test)) . array([&#34;Not Sure / Don&#39;t Recall&#34;], dtype=object) . Train_predict = clf.predict(X_Train) . (Train_predict == y_train).all() . False . from sklearn.metrics import accuracy_score, classification_report print(&#39;Accuracy is:&#39;, accuracy_score(y_train, Train_predict)) print(classification_report(y_train, Train_predict)) . Accuracy is: 0.5057011402280456 precision recall f1-score support 0 0.00 0.00 0.00 6 1 0.50 0.58 0.54 1907 2 0.50 0.63 0.56 2067 3 0.57 0.16 0.25 633 4 0.50 0.03 0.05 386 accuracy 0.51 4999 macro avg 0.41 0.28 0.28 4999 weighted avg 0.51 0.51 0.47 4999 . C: Users LENOVO anaconda3 lib site-packages sklearn metrics _classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) C: Users LENOVO anaconda3 lib site-packages sklearn metrics _classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) C: Users LENOVO anaconda3 lib site-packages sklearn metrics _classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior. _warn_prf(average, modifier, msg_start, len(result)) . Altair is a Python visualization library based on vega and vega-lite. The vega and vega lite are declarative programming languages where you specify properties of the graph as JSON and it plots graph based on that using Canvas or SVG. As Altair is built on top of these libraries, it provides almost the same functionalities as them in python. Altair&#39;s API is simple and easy to use which lets the developer spend more time on data analysis than getting visualizations right. First import all the necessary libraries to get started. . import altair as alt alt.renderers.enable(&#39;altair_viewer&#39;) . RendererRegistry.enable(&#39;altair_viewer&#39;) . df . year case_id weight weight_cumulative state st cong cong_up state_post st_post ... voted_rep_chosen voted_sen_chosen voted_gov_chosen rep_current rep_icpsr sen1_current sen1_icpsr sen2_current sen2_icpsr gov_current . 0 2006 | 439219 | 1.851676 | 1.667581 | North Carolina | NC | 109 | 110 | North Carolina | NC | ... | Richard C. Carsner (D) | | | Patrick T. McHenry (R) | 20522 | Elizabeth Dole (R) | 40303 | Richard Burr (R) | 29548 | Michael Easley (D) | . 1 2006 | 439224 | 0.968308 | 0.872039 | Ohio | OH | 109 | 110 | Ohio | OH | ... | Stephanie Studebaker (D) | Sherrod C. Brown (D) | Ted Strickland (D) | Michael R. Turner (R) | 20342 | Mike DeWine (R) | 15020 | George V. Voinovich (R) | 49903 | Bob Taft (R) | . 2 2006 | 439228 | 1.593441 | 1.435020 | New Jersey | NJ | 109 | 110 | New Jersey | NJ | ... | Robert E. Andrews (D) | Robert Menendez (D) | | Robert E. Andrews (D) | 29132 | Robert Menendez (D) | 29373 | Frank R. Lautenberg (D) | 14914 | Jon Corzine (D) | . 3 2006 | 439237 | 1.398529 | 1.259486 | Illinois | IL | 109 | 110 | Illinois | IL | ... | Janice D. Schakowsky (D) | | Rod Blagojevich (D) | Janice D. Schakowsky (D) | 29911 | Richard Durbin (D) | 15021 | Barack Obama (D) | 40502 | Rod Blagojevich (D) | . 4 2006 | 439238 | 0.902890 | 0.813124 | New York | NY | 109 | 110 | New York | NY | ... | Maurice D. Hinchey (D) | Hillary Rodham Clinton (D) | Eliot Spitzer (D) | Maurice D. Hinchey (D) | 29380 | Charles E. Schumer (D) | 14858 | Hillary Rodham Clinton (D) | 40105 | George Pataki (R) | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 531750 2020 | 1199586597 | 1.766100 | 0.949641 | Pennsylvania | PA | 116 | 117 | NaN | NaN | ... | | | | Scott Perry (R) | 21356 | Bob Casey Jr. (D) | 40703 | Pat Toomey (R) | 29935 | Tom Wolf (D) | . 531751 2020 | 1261249927 | 1.158300 | 0.622824 | Oregon | OR | 116 | 117 | Oregon | OR | ... | Peter DeFazio (D) | Jeff Merkley (D) | | Peter DeFazio (D) | 15410 | Ron Wyden (D) | 14871 | Jeff Merkley (D) | 40908 | Kate Brown (D) | . 531752 2020 | 1261247715 | 1.571700 | 0.845111 | Iowa | IA | 116 | 117 | Iowa | IA | ... | David Young (R) | Joni Ernst (R) | | Cindy Axne (D) | 21902 | Chuck Grassley (R) | 14226 | Joni Ernst (R) | 41502 | Kim Reynolds (R) | . 531753 2020 | 1257274335 | 1.011000 | 0.543620 | Texas | TX | 116 | 117 | NaN | NaN | ... | | | | Chip Roy (R) | 21961 | John Cornyn (R) | 40305 | Ted Cruz (R) | 41304 | Greg Abbott (R) | . 531754 2020 | 1261243127 | 0.737700 | 0.396665 | Ohio | OH | 116 | 117 | Ohio | OH | ... | | | | Troy Balderson (R) | 21759 | Sherrod Brown (D) | 29389 | Rob Portman (R) | 29386 | Mike DeWine (R) | . 531755 rows × 93 columns . altdata = df[(df[&#39;st&#39;] == &#39;CA&#39;) | (df[&#39;st&#39;] == &#39;NV&#39;) | (df[&#39;st&#39;] == &#39;AZ&#39;)| (df[&#39;st&#39;] == &#39;OR&#39;) | (df[&#39;st&#39;] == &#39;WA&#39;) | (df[&#39;st&#39;] == &#39;NM&#39;)] . altdata . year case_id weight weight_cumulative state st cong cong_up state_post st_post ... voted_rep_chosen voted_sen_chosen voted_gov_chosen rep_current rep_icpsr sen1_current sen1_icpsr sen2_current sen2_icpsr gov_current . 7 2006 | 439254 | 0.838927 | 0.755521 | Nevada | NV | 109 | 110 | Nevada | NV | ... | Jill Derby (D) | Jack Carter (D) | Dina Titus (D) | Jim Gibbons (R) | 29739 | Harry Reid (D) | 15054 | John Ensign (R) | 29537 | Kenny Guinn (R) | . 11 2006 | 439269 | 0.902890 | 0.813124 | California | CA | 109 | 110 | California | CA | ... | John W. Jones (R) | Richard &quot;Dick&quot; Mountjoy (R) | | Mike Thompson (D) | 29901 | Dianne Feinstein (D) | 49300 | Barbara Boxer (D) | 15011 | Arnold Schwarzenegger (R) | . 12 2006 | 439270 | 0.612356 | 0.551475 | California | CA | 109 | 110 | California | CA | ... | | Richard &quot;Dick&quot; Mountjoy (R) | Arnold Schwarzenegger (R) | Mike Thompson (D) | 29901 | Dianne Feinstein (D) | 49300 | Barbara Boxer (D) | 15011 | Arnold Schwarzenegger (R) | . 14 2006 | 439281 | 0.838927 | 0.755521 | Washington | WA | 109 | 110 | Washington | WA | ... | Darcy Burner (D) | Maria Cantwell (D) | | David G. Reichert (R) | 20536 | Patty Murray (D) | 49308 | Maria Cantwell (D) | 39310 | Christine Gregoire (D) | . 28 2006 | 439362 | 1.992852 | 1.794722 | Nevada | NV | 109 | 110 | Nevada | NV | ... | Jon C. Porter (R) | John Ensign (R) | Jim Gibbons (R) | Jon C. Porter (R) | 20334 | Harry Reid (D) | 15054 | John Ensign (R) | 29537 | Kenny Guinn (R) | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 531725 2020 | 1261090355 | 0.842700 | 0.453124 | California | CA | 116 | 117 | NaN | NaN | ... | | | | Scott Peters (D) | 21315 | Dianne Feinstein (D) | 49300 | Kamala Harris (D) | 41701 | Gavin Newsom (D) | . 531735 2020 | 1261191455 | 1.758000 | 0.945285 | Oregon | OR | 116 | 117 | NaN | NaN | ... | | | | Greg Walden (R) | 29932 | Ron Wyden (D) | 14871 | Jeff Merkley (D) | 40908 | Kate Brown (D) | . 531740 2020 | 1261130755 | 0.794500 | 0.427207 | Washington | WA | 116 | 117 | NaN | NaN | ... | | | | Cathy McMorris Rodgers (R) | 20535 | Patty Murray (D) | 49308 | Maria Cantwell (D) | 39310 | Jay Inslee (D) | . 531747 2020 | 1261149227 | 0.362800 | 0.195079 | California | CA | 116 | 117 | California | CA | ... | | | | Raul Ruiz (D) | 21311 | Dianne Feinstein (D) | 49300 | Kamala Harris (D) | 41701 | Gavin Newsom (D) | . 531751 2020 | 1261249927 | 1.158300 | 0.622824 | Oregon | OR | 116 | 117 | Oregon | OR | ... | Peter DeFazio (D) | Jeff Merkley (D) | | Peter DeFazio (D) | 15410 | Ron Wyden (D) | 14871 | Jeff Merkley (D) | 40908 | Kate Brown (D) | . 94905 rows × 93 columns . altdata=altdata[altdata[&#39;year&#39;] == 2016] . altdata=altdata.head(5000) . Common Steps to Generate Charts using Altair The generation of charts using Altair is a list of steps that are described below. These steps are commonly used to generate a chart using Altair. . Create a Chart object passing dataframe to it. Call marker type (mark_point(), mark_bar(), etc) on chart object to select chart type that will be plotted. Call encode() method on output from 2nd step passing it various plot properties. As a part of this step, provide details as to which column of the dataset will be used for what purpose. . alt.Chart(altdata).mark_bar().encode( x=&#39;age&#39;, y=&#39;voted_pres_16&#39;) . Displaying chart at http://localhost:20979/ alt.Chart(altdata).mark_circle().encode( x=&#39;age&#39;, y=&#39;voted_pres_16&#39;) . Displaying chart at http://localhost:20979/ alt.Chart(altdata).mark_circle().encode( x=&#39;st&#39;, y=&#39;age&#39;, color=&#39;voted_pres_16&#39;, size=&#39;dist&#39;) . Displaying chart at http://localhost:20979/ chart = alt.Chart(altdata).mark_point().encode( x=&#39;age&#39;, y=&#39;voted_pres_16&#39;, color=&#39;st:N&#39;, tooltip=&#39;st&#39;) chart+chart.transform_regression(&#39;age&#39;,&#39;voted_pres_16&#39;).mark_line() . Displaying chart at http://localhost:20979/ chart = alt.Chart(altdata).mark_point().encode( x=&#39;age&#39;, y=&#39;dist&#39;, color=&#39;voted_pres_16:N&#39;, tooltip=&#39;voted_pres_16&#39;) chart+chart.transform_regression(&#39;age&#39;,&#39;dist&#39;).mark_line() . Displaying chart at http://localhost:20979/ ageplot=alt.Chart(altdata).mark_circle().encode( x=&#39;age&#39;, y=&#39;voted_pres_16&#39;, color=&#39;st&#39;, tooltip=&#39;st&#39;, ) distplot=alt.Chart(altdata).mark_circle().encode( x=&#39;dist&#39;, y=&#39;voted_pres_16&#39;, color=&#39;st&#39;, tooltip=&#39;st&#39;, ) ageplot | distplot . Displaying chart at http://localhost:20979/ This is the end of the small exploratory data analysis for my data by introducing the basic API of Altair to plot basic charts using it. Thank you! .",
            "url": "https://rini278.github.io/finalsblog/2022/03/14/Finalproject.html",
            "relUrl": "/2022/03/14/Finalproject.html",
            "date": " • Mar 14, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://rini278.github.io/finalsblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://rini278.github.io/finalsblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rini278.github.io/finalsblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rini278.github.io/finalsblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}